{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391216e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0893bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = r'C:\\Users\\datsh\\Desktop\\Autopilot-TensorFlow-master\\driving_dataset'\n",
    "TRAIN_FILE = os.path.join(DATA_FOLDER, 'data.txt')\n",
    "LIMIT = None\n",
    "\n",
    "split = 0.8\n",
    "x, y = list(), list()\n",
    "\n",
    "with open(TRAIN_FILE) as fp:\n",
    "    for line in islice(fp, LIMIT):\n",
    "        path, angle = line.strip().split()\n",
    "        full_path = os.path.join(DATA_FOLDER, path)\n",
    "        \n",
    "        x.append(full_path)\n",
    "        y.append(float(angle)*(math.pi)*(1/180))\n",
    "\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "250f15c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  26.,   12.,   23.,   23.,   16.,   25.,    7.,    4.,    7.,\n",
       "           3.,    3.,    5.,    4.,    4.,    4.,    5.,    5.,   17.,\n",
       "          18.,   21.,   67.,   41.,   17.,   19.,   15.,   15.,   16.,\n",
       "          24.,   25.,  152.,  280.,  126.,  325.,  759., 2609.,  944.,\n",
       "        1806.,  727.,  245.,  258.,  132.,   30.,   20.,   53.,   75.,\n",
       "          46.,    6.,    4.,    5.,    9.]),\n",
       " array([-2.79130507, -2.70985405, -2.62840302, -2.546952  , -2.46550097,\n",
       "        -2.38404995, -2.30259892, -2.22114789, -2.13969687, -2.05824584,\n",
       "        -1.97679482, -1.89534379, -1.81389277, -1.73244174, -1.65099072,\n",
       "        -1.56953969, -1.48808866, -1.40663764, -1.32518661, -1.24373559,\n",
       "        -1.16228456, -1.08083354, -0.99938251, -0.91793149, -0.83648046,\n",
       "        -0.75502943, -0.67357841, -0.59212738, -0.51067636, -0.42922533,\n",
       "        -0.34777431, -0.26632328, -0.18487226, -0.10342123, -0.0219702 ,\n",
       "         0.05948082,  0.14093185,  0.22238287,  0.3038339 ,  0.38528492,\n",
       "         0.46673595,  0.54818697,  0.629638  ,  0.71108903,  0.79254005,\n",
       "         0.87399108,  0.9554421 ,  1.03689313,  1.11834415,  1.19979518,\n",
       "         1.2812462 ]),\n",
       " [<matplotlib.patches.Polygon at 0x178262f9520>])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Splitting the dataset and plotting the respective histograms\n",
    "\n",
    "split_index = int(len(y)*0.8)\n",
    "y_train = y[:split_index]\n",
    "y_test = y[split_index:]\n",
    "\n",
    "plt.hist(y_train, bins=50, color='red', histtype='step')\n",
    "plt.hist(y_test, bins=50, color='blue', histtype='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3001f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19112687369474946\n",
      "0.19089104348993743\n"
     ]
    }
   ],
   "source": [
    "# Regression problem\n",
    "\n",
    "y_mean_train = np.mean(y_train)\n",
    "print(np.mean(np.square(y_test - y_mean_train)))\n",
    "print(np.mean(np.square(y_test - 0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7be31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (STEP-1) Code for training the data (Necessary additional python files to be linked)\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "import driving_data\n",
    "import model\n",
    "import cv2\n",
    "from subprocess import call\n",
    "\n",
    "LOGDIR = './save'\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "L2NormConst = 0.001\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(model.y_, model.y))) + tf.add_n([tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V2)\n",
    "\n",
    "# op to write logs to Tensorboard\n",
    "logs_path = './logs'\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "\n",
    "# train over the dataset about 30 times\n",
    "for epoch in range(epochs):\n",
    "  for i in range(int(driving_data.num_images/batch_size)):\n",
    "    xs, ys = driving_data.LoadTrainBatch(batch_size)\n",
    "    train_step.run(feed_dict={model.x: xs, model.y_: ys, model.keep_prob: 0.8})\n",
    "    if i % 10 == 0:\n",
    "      xs, ys = driving_data.LoadValBatch(batch_size)\n",
    "      loss_value = loss.eval(feed_dict={model.x:xs, model.y_: ys, model.keep_prob: 1.0})\n",
    "      print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + i, loss_value))\n",
    "\n",
    "    # write logs at every iteration\n",
    "    summary = merged_summary_op.eval(feed_dict={model.x:xs, model.y_: ys, model.keep_prob: 1.0})\n",
    "    summary_writer.add_summary(summary, epoch * driving_data.num_images/batch_size + i)\n",
    "\n",
    "    if i % batch_size == 0:\n",
    "      if not os.path.exists(LOGDIR):\n",
    "        os.makedirs(LOGDIR)\n",
    "      checkpoint_path = os.path.join(LOGDIR, \"model.ckpt\")\n",
    "      filename = saver.save(sess, checkpoint_path)\n",
    "  print(\"Model saved in file: %s\" % filename)\n",
    "\n",
    "print(\"Run the command line:\\n\" \\\n",
    "      \"--> tensorboard --logdir=./logs \" \\\n",
    "      \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (STEP-2) Running the code (Necessary additional python files to be linked)\n",
    "\n",
    "#check if on windows OS\n",
    "windows = False\n",
    "if os.name == 'nt':\n",
    "    windows = True\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"save/model.ckpt\")\n",
    "\n",
    "img = cv2.imread('steering_wheel_image.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "smoothed_angle = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(cv2.waitKey(10) != ord('q')):\n",
    "    ret, frame = cap.read()\n",
    "    image = cv2.resize(frame, (200, 66)) / 255.0\n",
    "    degrees = model.y.eval(feed_dict={model.x: [image], model.keep_prob: 1.0})[0][0] * 180 / 3.14159265\n",
    "    if not windows:\n",
    "        call(\"clear\")\n",
    "    print(\"Predicted steering angle: \" + str(degrees) + \" degrees\")\n",
    "    cv2.imshow('frame', frame)\n",
    "    #make smooth angle transitions by turning the steering wheel based on the difference of the current angle\n",
    "    #and the predicted angle\n",
    "    smoothed_angle += 0.2 * pow(abs((degrees - smoothed_angle)), 2.0 / 3.0) * (degrees - smoothed_angle) / abs(degrees - smoothed_angle)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),-smoothed_angle,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imshow(\"steering wheel\", dst)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc963c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (STEP-3) Running the dataset (Necessary additional python files to be linked)\n",
    "\n",
    "#check if on windows OS\n",
    "windows = False\n",
    "if os.name == 'nt':\n",
    "    windows = True\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"save/model.ckpt\")\n",
    "\n",
    "img = cv2.imread('steering_wheel_image.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "smoothed_angle = 0\n",
    "\n",
    "i = 0\n",
    "while(cv2.waitKey(10) != ord('q')):\n",
    "    full_image = cv2.imread(\"driving_dataset/\" + str(i) + \".jpg\")\n",
    "    image = cv2.resize(full_image[-150:], (200, 66)) / 255.0\n",
    "    degrees = model.y.eval(feed_dict={model.x: [image], model.keep_prob: 1.0})[0][0] * 180.0 / 3.14159265\n",
    "    if not windows:\n",
    "        call(\"clear\")\n",
    "    print(\"Predicted steering angle: \" + str(degrees) + \" degrees\")\n",
    "    cv2.imshow(\"frame\", full_image)\n",
    "    #make smooth angle transitions by turning the steering wheel based on the difference of the current angle\n",
    "    #and the predicted angle\n",
    "    smoothed_angle += 0.2 * pow(abs((degrees - smoothed_angle)), 2.0 / 3.0) * (degrees - smoothed_angle) / abs(degrees - smoothed_angle)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),-smoothed_angle,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imshow(\"steering wheel\", dst)\n",
    "    i += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
